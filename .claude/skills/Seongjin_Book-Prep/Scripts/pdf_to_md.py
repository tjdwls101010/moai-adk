#!/usr/bin/env python3
"""
PDF to Markdown Converter with AI Image Descriptions

PDFë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ì´ë¯¸ì§€ì— AI ê¸°ë°˜ ì„¤ëª…ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
Gemini ë˜ëŠ” GPT ëª¨ë¸ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Usage:
    python pdf_to_md.py -p "path/to/file.pdf"           # ê¸°ë³¸: GPT ì‚¬ìš©
    python pdf_to_md.py -p "path/to/file.pdf" -m gpt    # GPT ì‚¬ìš©
    python pdf_to_md.py -p "path/to/file.pdf" -m gemini # Gemini ì‚¬ìš©
"""

import argparse
import asyncio
import base64
import hashlib
import json
import os
import re
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple

import PIL.Image
import pymupdf4llm
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ==================== ì„¤ì •ê°’ ====================
DPI = 150  # ì´ë¯¸ì§€ í•´ìƒë„
IMAGE_FORMAT = "png"  # ì´ë¯¸ì§€ í¬ë§· (png, jpg)
CONTEXT_CHARS = 1111  # ì´ë¯¸ì§€ ì•ë’¤ë¡œ ì¶”ì¶œí•  í…ìŠ¤íŠ¸ ê¸¸ì´
CONCURRENT = 555  # ë™ì‹œ ì²˜ë¦¬í•  ì´ë¯¸ì§€ ê°œìˆ˜
PROMPT_FILE = "prompt_book.md"  # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ
FILE_ENCODING = "utf-8"
BACKUP_EXTENSION = ".md.backup"
IMAGE_PATTERN = r'!\[([^\]]*)\]\(([^)]+)\)'

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë° ëª¨ë¸ëª… ë¡œë“œ
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4.1-mini")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
GOOGLE_MODEL = os.getenv("GOOGLE_MODEL", "gemini-3-pro-preview")


def parse_args():
    """CLI ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description="PDFë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•˜ê³  AI ì´ë¯¸ì§€ ì„¤ëª…ì„ ì¶”ê°€í•©ë‹ˆë‹¤."
    )
    parser.add_argument(
        "-p", "--pdf",
        required=True,
        help="ë³€í™˜í•  PDF íŒŒì¼ ê²½ë¡œ"
    )
    parser.add_argument(
        "-m", "--model",
        choices=["gemini", "gpt"],
        default="gpt",
        help="ì´ë¯¸ì§€ ë¶„ì„ì— ì‚¬ìš©í•  AI ëª¨ë¸ (ê¸°ë³¸ê°’: gpt)"
    )
    return parser.parse_args()


def convert_pdf_to_markdown(
    pdf_path: str,
    dpi: int = 150,
    image_format: str = "png"
) -> Tuple[str, str, str]:
    """
    PDFë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜

    PDF ê²½ë¡œê°€ ./folder1/folder2/file.pdfì´ë©´:
    - ì¶œë ¥ í´ë”: ./folder1/folder2/ (PDFì™€ ê°™ì€ í´ë”)
    - ë§ˆí¬ë‹¤ìš´: ./folder1/folder2/file.md
    - ì´ë¯¸ì§€: ./folder1/folder2/images/ (ê³µí†µ í´ë”)

    Returns:
        (output_folder, markdown_file_path, cache_file_path)
    """
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    pdf_file = Path(pdf_path)
    if not pdf_file.exists():
        raise FileNotFoundError(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")

    # ì¶œë ¥ í´ë”ëŠ” PDFì™€ ê°™ì€ í´ë”
    pdf_stem = pdf_file.stem
    output_folder = pdf_file.parent

    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ
    markdown_file = output_folder / f"{pdf_stem}.md"

    # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ (ê³µí†µ images í´ë”)
    image_dir_abs = output_folder / "images"
    image_dir_abs.mkdir(parents=True, exist_ok=True)

    image_dir_relative = str(image_dir_abs)

    print(f"ğŸ”„ PDF ë³€í™˜ ì‹œì‘...")
    print(f"ğŸ“„ ì…ë ¥: {pdf_path}")
    print(f"ğŸ“ ì¶œë ¥ í´ë”: {output_folder}")
    print(f"ğŸ“„ ë§ˆí¬ë‹¤ìš´: {markdown_file}")
    print(f"ğŸ–¼ï¸  ì´ë¯¸ì§€ ì €ì¥: {image_dir_abs}")

    # PDF ë³€í™˜
    markdown_text = pymupdf4llm.to_markdown(
        str(pdf_file),
        page_chunks=False,
        write_images=True,
        image_path=image_dir_relative,
        image_format=image_format,
        dpi=dpi
    )

    # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ìƒëŒ€ ê²½ë¡œë¡œ ìˆ˜ì •
    print(f"\nğŸ”§ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ìƒëŒ€ ê²½ë¡œë¡œ ìˆ˜ì • ì¤‘...")

    folder_prefix = str(output_folder.resolve())

    markdown_text = re.sub(
        rf'!\[([^\]]*)\]\({re.escape(folder_prefix)}/images/',
        r'![\1](images/',
        markdown_text
    )

    markdown_text = re.sub(
        rf'!\[([^\]]*)\]\({re.escape(str(output_folder))}/images/',
        r'![\1](images/',
        markdown_text
    )

    markdown_text = re.sub(
        r'!\[([^\]]*)\]\(.*/images/images/',
        r'![\1](images/',
        markdown_text
    )

    print(f"âœ… ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì • ì™„ë£Œ")

    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥
    markdown_file.write_text(markdown_text, encoding="utf-8")

    # ìºì‹œ íŒŒì¼ ê²½ë¡œ (ì¶œë ¥ í´ë”ì— image-cache_[í´ë”ëª…].json í˜•ì‹ìœ¼ë¡œ ì €ì¥)
    cache_file = output_folder / f"image-cache_{pdf_stem}.json"

    file_size_kb = len(markdown_text.encode("utf-8")) / 1024
    print(f"\nâœ… ë³€í™˜ ì™„ë£Œ!")
    print(f"ğŸ“„ ë§ˆí¬ë‹¤ìš´: {markdown_file}")
    print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size_kb:.2f} KB")
    print(f"ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(markdown_text):,} ë¬¸ì")
    print(f"ğŸ’¾ ìºì‹œ íŒŒì¼: {cache_file}")

    return str(output_folder), str(markdown_file), str(cache_file)


@dataclass
class ImageMatch:
    """ì´ë¯¸ì§€ ë§¤ì¹˜ ì •ë³´"""
    full_match: str
    alt_text: str
    image_path: str
    start_pos: int
    end_pos: int
    context_before: str
    context_after: str


class ImageDescriber:
    """ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±ê¸°"""

    def __init__(
        self,
        markdown_path: str,
        model_type: str = "gpt",
        context_chars: int = 1111,
        concurrent: int = 555,
        cache_file: str = ".image_cache.json",
        prompt_file: str = "prompt_book.md"
    ):
        self.markdown_path = Path(markdown_path)
        self.model_type = model_type.lower()
        self.context_chars = context_chars
        self.concurrent = concurrent
        self.cache_file = Path(cache_file)
        self.prompt_file = Path(prompt_file)

        self.cache = self._load_cache()
        self._load_prompt_template()

        # ëª¨ë¸ ì´ˆê¸°í™”
        if self.model_type == "gemini":
            self._init_gemini()
        else:
            self._init_openai()

        self.processed_count = 0
        self.total_count = 0
        self.lock = None

    def _load_cache(self) -> Dict:
        """ìºì‹œ ë¡œë“œ"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding=FILE_ENCODING) as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

    def _save_cache(self):
        """ìºì‹œ ì €ì¥"""
        try:
            with open(self.cache_file, 'w', encoding=FILE_ENCODING) as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _init_gemini(self):
        """Gemini ì´ˆê¸°í™”"""
        import google.generativeai as genai

        if not GOOGLE_API_KEY:
            raise ValueError("GOOGLE_API_KEY ë˜ëŠ” GEMINI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        genai.configure(api_key=GOOGLE_API_KEY)
        self.gemini_client = genai.GenerativeModel(GOOGLE_MODEL)
        self.model_name = GOOGLE_MODEL
        print(f"ğŸ¤– Gemini ëª¨ë¸ ì´ˆê¸°í™”: {GOOGLE_MODEL}")

    def _init_openai(self):
        """OpenAI ì´ˆê¸°í™”"""
        from openai import OpenAI

        if not OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.openai_client = OpenAI(api_key=OPENAI_API_KEY)
        self.model_name = OPENAI_MODEL
        print(f"ğŸ¤– OpenAI ëª¨ë¸ ì´ˆê¸°í™”: {OPENAI_MODEL}")

    def _load_prompt_template(self):
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ"""
        try:
            with open(self.prompt_file, 'r', encoding=FILE_ENCODING) as f:
                self.prompt_template = f.read()
            print(f"âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ: {self.prompt_file}")
        except FileNotFoundError:
            print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.prompt_file}")
            print(f"âš ï¸ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.prompt_template = """ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì„¤ëª…ì„ ìƒì„±í•˜ì„¸ìš”.

Context before: {context_before}
Context after: {context_after}
Image: {image_path}"""
        except Exception as e:
            print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.prompt_template = "ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì„¸ìš”."

    def find_images(self, content: str) -> List[ImageMatch]:
        """ë§ˆí¬ë‹¤ìš´ì—ì„œ ì´ë¯¸ì§€ ì°¾ê¸°"""
        matches = []

        for match in re.finditer(IMAGE_PATTERN, content):
            alt_text = match.group(1)
            image_path = match.group(2)
            start_pos = match.start()
            end_pos = match.end()

            context_start = max(0, start_pos - self.context_chars)
            context_end = min(len(content), end_pos + self.context_chars)

            context_before = content[context_start:start_pos].strip()
            context_after = content[end_pos:context_end].strip()

            matches.append(ImageMatch(
                full_match=match.group(0),
                alt_text=alt_text,
                image_path=image_path,
                start_pos=start_pos,
                end_pos=end_pos,
                context_before=context_before,
                context_after=context_after
            ))

        return matches

    def _get_cache_key(self, image_match: ImageMatch) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = f"{image_match.image_path}:{image_match.context_before}:{image_match.context_after}"
        return hashlib.md5(key_data.encode()).hexdigest()

    async def describe_image_gemini(self, image_match: ImageMatch, image_path: Path) -> str:
        """Geminië¡œ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±"""
        prompt = self.prompt_template.format(
            image_match=image_match,
            context_before=image_match.context_before,
            context_after=image_match.context_after,
            image_path=str(image_path)
        )

        try:
            img = PIL.Image.open(image_path)
            response = await asyncio.to_thread(
                self.gemini_client.generate_content,
                [prompt, img]
            )
            return response.text.strip()
        except Exception as e:
            print(f"  âŒ Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return "ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨"

    async def describe_image_gpt(self, image_match: ImageMatch, image_path: Path) -> str:
        """GPTë¡œ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±"""
        prompt = self.prompt_template.format(
            image_match=image_match,
            context_before=image_match.context_before,
            context_after=image_match.context_after,
            image_path=str(image_path)
        )

        try:
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            with open(image_path, "rb") as f:
                image_data = f.read()
            base64_image = base64.b64encode(image_data).decode('utf-8')

            # ì´ë¯¸ì§€ í¬ë§· í™•ì¸
            suffix = image_path.suffix.lower()
            if suffix == ".png":
                media_type = "image/png"
            elif suffix in [".jpg", ".jpeg"]:
                media_type = "image/jpeg"
            elif suffix == ".webp":
                media_type = "image/webp"
            elif suffix == ".gif":
                media_type = "image/gif"
            else:
                media_type = "image/png"

            response = await asyncio.to_thread(
                self.openai_client.chat.completions.create,
                model=self.model_name,
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{media_type};base64,{base64_image}"
                            }
                        }
                    ]
                }],
                max_completion_tokens=4096
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"  âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return "ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨"

    async def describe_image(self, image_match: ImageMatch) -> str:
        """ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± (ìºì‹œ í™œìš©)"""
        cache_key = self._get_cache_key(image_match)

        # ìºì‹œ í™•ì¸
        if cache_key in self.cache:
            print(f"  âœ“ ìºì‹œì—ì„œ ë¡œë“œ: {image_match.image_path}")
            cached_data = self.cache[cache_key]
            if isinstance(cached_data, dict):
                return cached_data["description"]
            else:
                return cached_data

        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        image_path = self.markdown_path.parent / image_match.image_path

        if not image_path.exists():
            print(f"  âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {image_path}")
            return "ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ"

        print(f"  ğŸ” ë¶„ì„ ì¤‘: {image_match.image_path}")

        # ëª¨ë¸ì— ë”°ë¼ ì ì ˆí•œ API í˜¸ì¶œ
        if self.model_type == "gemini":
            description = await self.describe_image_gemini(image_match, image_path)
        else:
            description = await self.describe_image_gpt(image_match, image_path)

        # ìºì‹œì— ì €ì¥
        self.cache[cache_key] = {
            "description": description,
            "timestamp": datetime.now().isoformat(),
            "model": self.model_name
        }
        self._save_cache()

        return description

    async def process_images(self, matches: List[ImageMatch]) -> List[Tuple[ImageMatch, str]]:
        """ì´ë¯¸ì§€ ë³‘ë ¬ ì²˜ë¦¬"""
        self.total_count = len(matches)
        self.processed_count = 0
        self.lock = asyncio.Lock()

        semaphore = asyncio.Semaphore(self.concurrent)

        async def process_with_semaphore(match):
            async with semaphore:
                description = await self.describe_image(match)
                async with self.lock:
                    self.processed_count += 1
                    if self.processed_count % 10 == 0 or self.processed_count == self.total_count:
                        print(f"\nğŸ“Š ì§„í–‰ë¥ : {self.processed_count}/{self.total_count} ({self.processed_count*100//self.total_count}%)")
                return (match, description)

        tasks = [process_with_semaphore(match) for match in matches]
        results = await asyncio.gather(*tasks)

        print(f"\n{'='*60}")
        print(f"âœ… ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ: {self.total_count}ê°œ")
        print(f"{'='*60}\n")

        return results

    def update_markdown(self, content: str, results: List[Tuple[ImageMatch, str]]) -> str:
        """ë§ˆí¬ë‹¤ìš´ ì—…ë°ì´íŠ¸"""
        results_sorted = sorted(results, key=lambda x: x[0].start_pos, reverse=True)

        for match, description in results_sorted:
            description = description.replace('\n', ' ').strip()
            new_text = f"![{description}]({match.image_path})"
            content = content[:match.start_pos] + new_text + content[match.end_pos:]

        return content

    async def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        print(f"\nğŸ“ ë§ˆí¬ë‹¤ìš´ íŒŒì¼: {self.markdown_path}")
        print(f"ğŸ¤– LLM: {self.model_name} ({self.model_type})")
        print(f"âš¡ ë™ì‹œ ì²˜ë¦¬: {self.concurrent}")
        print(f"ğŸ“ Context ê¸¸ì´: {self.context_chars}ì")
        print(f"ğŸ“‹ í”„ë¡¬í”„íŠ¸: {self.prompt_file}\n")

        # íŒŒì¼ ì½ê¸°
        with open(self.markdown_path, 'r', encoding=FILE_ENCODING) as f:
            content = f.read()

        # ì´ë¯¸ì§€ ì°¾ê¸°
        matches = self.find_images(content)
        print(f"ğŸ–¼ï¸  ë°œê²¬í•œ ì´ë¯¸ì§€: {len(matches)}ê°œ\n")

        if not matches:
            print("ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì´ë¯¸ì§€ ì²˜ë¦¬
        results = await self.process_images(matches)

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ì²˜ë¦¬ ê²°ê³¼:")
        print("="*60)
        for match, description in results[:5]:
            print(f"\nğŸ“ {match.image_path}")
            print(f"   {description[:100]}...")

        # ë§ˆí¬ë‹¤ìš´ ì—…ë°ì´íŠ¸
        updated_content = self.update_markdown(content, results)

        # ë°±ì—… ìƒì„±
        backup_path = Path(str(self.markdown_path) + BACKUP_EXTENSION)
        with open(backup_path, 'w', encoding=FILE_ENCODING) as f:
            f.write(content)
        print(f"\nğŸ’¾ ë°±ì—… ìƒì„±: {backup_path}")

        # íŒŒì¼ ì €ì¥
        with open(self.markdown_path, 'w', encoding=FILE_ENCODING) as f:
            f.write(updated_content)
        print(f"âœ… íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {self.markdown_path}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()

    print("\n" + "="*60)
    print("ğŸ“š PDF to Markdown Converter with AI Image Descriptions")
    print("="*60)
    print(f"ğŸ“„ PDF: {args.pdf}")
    print(f"ğŸ¤– ëª¨ë¸: {args.model}")
    print("="*60 + "\n")

    # 1. PDF -> ë§ˆí¬ë‹¤ìš´ ë³€í™˜
    output_folder, markdown_file, cache_file = convert_pdf_to_markdown(
        pdf_path=args.pdf,
        dpi=DPI,
        image_format=IMAGE_FORMAT
    )

    # 2. ì´ë¯¸ì§€ ì„¤ëª… ì¶”ê°€
    # prompt_file ê²½ë¡œ ì„¤ì • (ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆë‹¤ê³  ê°€ì •)
    script_dir = Path(__file__).parent
    prompt_file = script_dir / PROMPT_FILE

    describer = ImageDescriber(
        markdown_path=markdown_file,
        model_type=args.model,
        context_chars=CONTEXT_CHARS,
        concurrent=CONCURRENT,
        cache_file=cache_file,
        prompt_file=str(prompt_file)
    )

    asyncio.run(describer.run())

    print("\n" + "="*60)
    print("ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {markdown_file}")
    print("="*60 + "\n")


if __name__ == "__main__":
    main()
